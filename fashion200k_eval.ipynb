{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--output-dir'], dest='output_dir', nargs=None, const=None, default='./results', type=<class 'str'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from utils import get_embeddings, run_retrieval, evaluate_retrieval, setup_logging\n",
    "from data.utils import get_dataset\n",
    "from models import load_model\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Args for datasets\n",
    "parser.add_argument(\"--data-dir\", type=str, default=\"./data/\", help='Data directory.')\n",
    "parser.add_argument('--dataset-config', default='./configs/fashion200k.json', help='Dataset config file.')\n",
    "parser.add_argument(\"--batch-size\", type=int, default=512)\n",
    "parser.add_argument(\"--num-workers\", type=int, default=4)\n",
    "# Args for models\n",
    "parser.add_argument('--model-name', type=str, default='ViT-B-16', help='Model name.')\n",
    "parser.add_argument('--run-name', type=str, default='ViT-B-16_laion2b_s34b_b88k', help='Run name.')\n",
    "parser.add_argument(\"--pretrained\", type=str, default='laion2b_s34b_b88k', help='Pretrained name.')\n",
    "parser.add_argument('--cache-dir', default=\"/home/jupyter/cache\", help='Cache directory for models and datasets.')\n",
    "parser.add_argument('--device', default='cuda', help='Device to use for inference.')\n",
    "parser.add_argument(\"--query-prefix\", type=str, default='', help=\"Query prefix if required (ex. 'description: ')\")\n",
    "# Args for evaluations\n",
    "parser.add_argument('--Ks', default=[1, 10], nargs='+', help='Ks for metrics.')\n",
    "parser.add_argument(\"--overwrite-embeddings\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--overwrite-retrieval\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--output-dir\", type=str, default='./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = []\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06,22:58:13 | WARNING | Output directory ./results/fashion200k/ViT-B-16_laion2b_s34b_b88k exists. Ignore this if it is expected.\n",
      "2025-01-06,22:58:13 | INFO | Dataset: Fashion200k\n"
     ]
    }
   ],
   "source": [
    "setup_logging()\n",
    "# Output directory settings\n",
    "args.output_dir = os.path.join(args.output_dir, os.path.basename(args.dataset_config).replace('.json',''), args.run_name)\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "else:\n",
    "    logging.warning(f'Output directory {args.output_dir} exists. Ignore this if it is expected.')\n",
    "with open(os.path.join(args.output_dir, 'args.json'), 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=4)\n",
    "args.embeddings_path = os.path.join(args.output_dir, \"embeddings.pt\")\n",
    "\n",
    "# Read dataset config file\n",
    "with open(args.dataset_config, 'r') as file:\n",
    "    args.dataset_config = json.load(file)\n",
    "logging.info(\"Dataset: \" + args.dataset_config[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06,22:58:15 | INFO | Created a temporary directory at /var/tmp/tmphkaml1mf\n",
      "2025-01-06,22:58:15 | INFO | Writing /var/tmp/tmphkaml1mf/_remote_module_non_scriptable.py\n",
      "2025-01-06,22:58:15 | INFO | Loaded ViT-B-16 model config.\n",
      "2025-01-06,22:58:17 | INFO | Loading pretrained ViT-B-16 weights (laion2b_s34b_b88k).\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, preprocess, tokenizer = load_model(args)\n",
    "\n",
    "# Load documenets and generate embeddings\n",
    "model = model.to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06,22:58:23 | INFO | Loading dataset from huggingface.\n",
      "D2: <dict object at 0x7fdb8967e140>\n",
      "T4: <class 'datasets.data_files.DataFilesDict'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdc6c3b3320>\n",
      "T4: <class 'datasets.data_files.DataFilesList'>\n",
      "# T4\n",
      "T4: <class 'datasets.data_files.Url'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdbb67d65f0>\n",
      "# D2\n",
      "# D2\n",
      "# D2\n",
      "2025-01-06,22:58:24 | INFO | Using custom data configuration Marqo--fashion200k-e452c40783d60867\n",
      "2025-01-06,22:58:24 | INFO | Overwrite dataset info from restored data version if exists.\n",
      "2025-01-06,22:58:24 | INFO | Loading Dataset info from /home/jupyter/cache/datasets/Marqo___parquet/Marqo--fashion200k-e452c40783d60867/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7\n",
      "2025-01-06,22:58:24 | WARNING | Found cached dataset parquet (/home/jupyter/cache/datasets/Marqo___parquet/Marqo--fashion200k-e452c40783d60867/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "2025-01-06,22:58:24 | INFO | Loading Dataset info from /home/jupyter/cache/datasets/Marqo___parquet/Marqo--fashion200k-e452c40783d60867/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa43fcd416e34f1c99fc0dc9d85252c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4: <class 'data.utils.Transform'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdba4f585f0>\n",
      "T4: <class 'open_clip.tokenizer.SimpleTokenizer'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdc6c20f870>\n",
      "D2: <dict object at 0x7fdbac959370>\n",
      "# D2\n",
      "D2: <dict object at 0x7fdba40e0dc0>\n",
      "# D2\n",
      "D2: <dict object at 0x7fdb8a391cd0>\n",
      "# D2\n",
      "D2: <dict object at 0x7fdba40e0cd0>\n",
      "# D2\n",
      "D2: <dict object at 0x7fdb8a391d20>\n",
      "# D2\n",
      "D2: <dict object at 0x7fdba40e0c30>\n",
      "# D2\n",
      "Re: regex.Regex(\"<start_of_text>|<end_of_text>|'s|'t|'re|'ve|'m|'ll|'d|[\\\\p{L}]+|[\\\\p{N}]|[^\\\\s\\\\p{L}\\\\p{N}]+\", flags=regex.I | regex.V0)\n",
      "F2: <function compile at 0x7fdbaca90200>\n",
      "# F2\n",
      "# Re\n",
      "F2: <function _clean_lower at 0x7fdbaca90a70>\n",
      "# F2\n",
      "# D2\n",
      "T4: <class 'torchvision.transforms.transforms.Compose'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdba40e0fa0>\n",
      "T4: <class 'torchvision.transforms.transforms.Resize'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdba40e70f0>\n",
      "T4: <class 'collections.OrderedDict'>\n",
      "# T4\n",
      "T1: <class 'set'>\n",
      "F2: <function _load_type at 0x7fdbc40a1b00>\n",
      "# F2\n",
      "# T1\n",
      "T4: <enum 'InterpolationMode'>\n",
      "# T4\n",
      "# D2\n",
      "T4: <class 'torchvision.transforms.transforms.CenterCrop'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdba40e7140>\n",
      "# D2\n",
      "F2: <function _convert_to_rgb at 0x7fdbacb8f5f0>\n",
      "# F2\n",
      "T4: <class 'torchvision.transforms.transforms.ToTensor'>\n",
      "# T4\n",
      "T4: <class 'torchvision.transforms.transforms.Normalize'>\n",
      "# T4\n",
      "D2: <dict object at 0x7fdba40e7320>\n",
      "# D2\n",
      "# D2\n",
      "# D2\n",
      "2025-01-06,22:58:30 | INFO | Number of document rows: 201,624\n"
     ]
    }
   ],
   "source": [
    "doc_dataset, item_ID = get_dataset(args, tokenizer, preprocess)\n",
    "logging.info(f\"Number of document rows: {len(doc_dataset):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.isfile(args.embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06,22:58:30 | INFO | Getting embeddings of documents\n",
      "100%|██████████| 394/394 [1:07:18<00:00, 10.25s/it]\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(args.embeddings_path) or args.overwrite_embeddings:\n",
    "    logging.info(\"Getting embeddings of documents\")\n",
    "    embeddings = get_embeddings(model, doc_dataset, args)\n",
    "    torch.save(embeddings, args.embeddings_path)\n",
    "else:\n",
    "    logging.info(\"Loading embeddings of documents\")\n",
    "    embeddings = torch.load(args.embeddings_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07,00:07:58 | INFO | Task: {\n",
      "    \"name\": \"text-to-image\",\n",
      "    \"query_col\": [\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\"\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:07:58 | INFO | Loading ground truth\n",
      "2025-01-07,00:07:58 | INFO | Running retrieval\n",
      "100%|██████████| 2000/2000 [01:32<00:00, 21.56it/s]\n",
      "2025-01-07,00:09:31 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:31 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | NDCG@1: 0.0630\n",
      "2025-01-07,00:09:31 | INFO | NDCG@10: 0.1365\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | MAP@1: 0.0624\n",
      "2025-01-07,00:09:31 | INFO | MAP@10: 0.1075\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | Recall@1: 0.0624\n",
      "2025-01-07,00:09:31 | INFO | Recall@10: 0.2297\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | P@1: 0.0630\n",
      "2025-01-07,00:09:31 | INFO | P@10: 0.0238\n",
      "2025-01-07,00:09:32 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.06242,\n",
      "        \"MAP@10\": 0.10752\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.063,\n",
      "        \"NDCG@10\": 0.13649\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.063,\n",
      "        \"P@10\": 0.02375\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.06242,\n",
      "        \"Recall@10\": 0.2297\n",
      "    },\n",
      "    \"MRR\": 0.10791\n",
      "}\n",
      "2025-01-07,00:09:32 | INFO | Task: {\n",
      "    \"name\": \"category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category1\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:32 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:32 | INFO | Running retrieval\n",
      "100%|██████████| 5/5 [00:00<00:00, 21.51it/s]\n",
      "2025-01-07,00:09:33 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:33 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | NDCG@1: 1.0000\n",
      "2025-01-07,00:09:33 | INFO | NDCG@10: 0.9843\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | MAP@1: 0.0000\n",
      "2025-01-07,00:09:33 | INFO | MAP@10: 0.0003\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | Recall@1: 0.0000\n",
      "2025-01-07,00:09:33 | INFO | Recall@10: 0.0003\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | P@1: 1.0000\n",
      "2025-01-07,00:09:33 | INFO | P@10: 0.9800\n",
      "2025-01-07,00:09:33 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 3e-05,\n",
      "        \"MAP@10\": 0.00026\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 1.0,\n",
      "        \"NDCG@10\": 0.98432\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 1.0,\n",
      "        \"P@10\": 0.98\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 3e-05,\n",
      "        \"Recall@10\": 0.00027\n",
      "    },\n",
      "    \"MRR\": 1.0\n",
      "}\n",
      "2025-01-07,00:09:33 | INFO | Task: {\n",
      "    \"name\": \"sub-category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category2\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:33 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:33 | INFO | Running retrieval\n",
      "100%|██████████| 31/31 [00:01<00:00, 21.68it/s]\n",
      "2025-01-07,00:09:35 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:35 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | NDCG@1: 0.6129\n",
      "2025-01-07,00:09:35 | INFO | NDCG@10: 0.6035\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | MAP@1: 0.0002\n",
      "2025-01-07,00:09:35 | INFO | MAP@10: 0.0013\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | Recall@1: 0.0002\n",
      "2025-01-07,00:09:35 | INFO | Recall@10: 0.0015\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | P@1: 0.6129\n",
      "2025-01-07,00:09:35 | INFO | P@10: 0.6032\n",
      "2025-01-07,00:09:35 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.00017,\n",
      "        \"MAP@10\": 0.00129\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.6129,\n",
      "        \"NDCG@10\": 0.6035\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.6129,\n",
      "        \"P@10\": 0.60323\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.00017,\n",
      "        \"Recall@10\": 0.0015\n",
      "    },\n",
      "    \"MRR\": 0.73342\n",
      "}\n",
      "2025-01-07,00:09:35 | INFO | Task: {\n",
      "    \"name\": \"fine-category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category3\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:35 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:35 | INFO | Running retrieval\n",
      "100%|██████████| 2000/2000 [01:32<00:00, 21.61it/s]\n",
      "2025-01-07,00:11:08 | INFO | Evaluation Starts\n",
      "2025-01-07,00:11:08 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | NDCG@1: 0.0805\n",
      "2025-01-07,00:11:08 | INFO | NDCG@10: 0.1075\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | MAP@1: 0.0391\n",
      "2025-01-07,00:11:08 | INFO | MAP@10: 0.0783\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | Recall@1: 0.0391\n",
      "2025-01-07,00:11:08 | INFO | Recall@10: 0.1460\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | P@1: 0.0805\n",
      "2025-01-07,00:11:08 | INFO | P@10: 0.0374\n",
      "2025-01-07,00:11:08 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.03915,\n",
      "        \"MAP@10\": 0.07826\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0805,\n",
      "        \"NDCG@10\": 0.10754\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0805,\n",
      "        \"P@10\": 0.0374\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.03915,\n",
      "        \"Recall@10\": 0.14596\n",
      "    },\n",
      "    \"MRR\": 0.11935\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Run tasks\n",
    "for task in args.dataset_config[\"tasks\"]:\n",
    "    task_dir = os.path.join(args.output_dir, task['name'])\n",
    "    if not os.path.exists(task_dir):\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "    logging.info(f'Task: {json.dumps(task, indent=4)}')\n",
    "\n",
    "    for query_col in task[\"query_col\"]:\n",
    "        gt_dir = os.path.join(args.data_dir, args.dataset_config[\"name\"], 'gt_query_doc')\n",
    "        gt_results_path = os.path.join(gt_dir, f\"ground_truth_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        assert os.path.exists(gt_results_path)\n",
    "\n",
    "        # Ground-truth query-doc\n",
    "        logging.info(\"Loading ground truth\")\n",
    "        with open(gt_results_path, \"r\") as f:\n",
    "            gt_results = json.load(f)\n",
    "            test_queries = list(gt_results.keys()) # randomly sampled queries (up to 2000)\n",
    "        \n",
    "        # Running retrieval\n",
    "        retrieval_path = os.path.join(task_dir, f\"retrieved_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        if os.path.exists(retrieval_path) and not args.overwrite_retrieval:\n",
    "            logging.info(\"Loading retrieval\")\n",
    "            with open(retrieval_path, \"r\") as f:\n",
    "                retrieval_results = json.load(f)\n",
    "        else:\n",
    "            logging.info(\"Running retrieval\")\n",
    "            if len(task['doc_col'])==1:\n",
    "                doc_embeddings = embeddings[task['doc_col'][0]].to(args.device)\n",
    "            else:\n",
    "                assert ('doc_weights' in task and len(task['doc_weights'])==len(task['doc_col'])), \\\n",
    "                    \"Must provide the same number of weights for multi-field documents as the number of multi-fields.\"\n",
    "                doc_embeddings = F.normalize(torch.stack([w*embeddings[c] for c, w in zip(task['doc_col'], task['doc_weights'])], dim=1).sum(1), dim=-1).to(args.device)\n",
    "            retrieval_results = run_retrieval(test_queries, item_ID, doc_embeddings, tokenizer, model, max(args.Ks), args)\n",
    "            with open(retrieval_path, \"w\") as f:\n",
    "                json.dump(retrieval_results, f, indent=4)\n",
    "\n",
    "        # Evaluation Starts\n",
    "        logging.info(\"Evaluation Starts\")\n",
    "        output_results = evaluate_retrieval(gt_results, retrieval_results, args)\n",
    "        output_json = os.path.join(task_dir, f\"result_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        output_json_dict = json.dumps(output_results, indent=4)\n",
    "        logging.info(output_json_dict)\n",
    "        with open(output_json, 'w') as f:\n",
    "            f.write(output_json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
