{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_StoreAction(option_strings=['--output-dir'], dest='output_dir', nargs=None, const=None, default='./results', type=<class 'str'>, choices=None, help=None, metavar=None)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "from utils import get_embeddings, run_retrieval, evaluate_retrieval, setup_logging\n",
    "from data.utils import get_dataset\n",
    "from models import load_model\n",
    "import torch.nn.functional as F\n",
    "import logging\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "# 'ViT-B-16' ; default\n",
    "# 'laion2b_s34b_b88k'; default pretrained\n",
    "model_name = \"Marqo/marqo-fashionSigLIP\"\n",
    "\n",
    "# Args for datasets\n",
    "parser.add_argument(\"--data-dir\", type=str, default=\"./data/\", help='Data directory.')\n",
    "parser.add_argument('--dataset-config', default='./configs/uniqlo_curated.json', help='Dataset config file.')\n",
    "parser.add_argument(\"--batch-size\", type=int, default=512)\n",
    "parser.add_argument(\"--num-workers\", type=int, default=4)\n",
    "# Args for models\n",
    "\n",
    "parser.add_argument('--model-name', type=str, default=model_name, help='Model name.')\n",
    "parser.add_argument('--run-name', type=str, default=model_name, help='Run name.')\n",
    "parser.add_argument(\"--pretrained\", type=str, default=None, help='Pretrained name.')\n",
    "parser.add_argument('--cache-dir', default=\"/home/jupyter/cache\", help='Cache directory for models and datasets.')\n",
    "parser.add_argument('--device', default='cuda', help='Device to use for inference.')\n",
    "parser.add_argument(\"--query-prefix\", type=str, default='', help=\"Query prefix if required (ex. 'description: ')\")\n",
    "# Args for evaluations\n",
    "parser.add_argument('--Ks', default=[1, 10], nargs='+', help='Ks for metrics.')\n",
    "parser.add_argument(\"--overwrite-embeddings\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--overwrite-retrieval\", action=\"store_true\", default=False)\n",
    "parser.add_argument(\"--output-dir\", type=str, default='./results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.argv = []\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13,21:10:23 | WARNING | Output directory ./results/uniqlo_curated/Marqo/marqo-fashionSigLIP exists. Ignore this if it is expected.\n",
      "2025-01-13,21:10:23 | INFO | Dataset: UniqloCurated\n"
     ]
    }
   ],
   "source": [
    "setup_logging()\n",
    "# Output directory settings\n",
    "args.output_dir = os.path.join(args.output_dir, os.path.basename(args.dataset_config).replace('.json',''), args.run_name)\n",
    "if not os.path.exists(args.output_dir):\n",
    "    os.makedirs(args.output_dir, exist_ok=True)\n",
    "else:\n",
    "    logging.warning(f'Output directory {args.output_dir} exists. Ignore this if it is expected.')\n",
    "with open(os.path.join(args.output_dir, 'args.json'), 'w') as f:\n",
    "    json.dump(args.__dict__, f, indent=4)\n",
    "args.embeddings_path = os.path.join(args.output_dir, \"embeddings.pt\")\n",
    "\n",
    "# Read dataset config file\n",
    "with open(args.dataset_config, 'r') as file:\n",
    "    args.dataset_config = json.load(file)\n",
    "logging.info(\"Dataset: \" + args.dataset_config[\"name\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13,21:10:30 | INFO | Created a temporary directory at /var/tmp/tmp94iq_sbe\n",
      "2025-01-13,21:10:30 | INFO | Writing /var/tmp/tmp94iq_sbe/_remote_module_non_scriptable.py\n",
      "2025-01-13,21:10:31 | INFO | Loaded hf-hub:Marqo/marqo-fashionSigLIP model config.\n",
      "2025-01-13,21:10:34 | INFO | Loading pretrained hf-hub:Marqo/marqo-fashionSigLIP weights (/home/jupyter/cache/models--Marqo--marqo-fashionSigLIP/snapshots/e5619578fd528afa0bf88d8fae37748336a57fa2/open_clip_pytorch_model.bin).\n"
     ]
    }
   ],
   "source": [
    "# Load model\n",
    "model, preprocess, tokenizer = load_model(args)\n",
    "\n",
    "# Load documenets and generate embeddings\n",
    "model = model.to(args.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13,21:10:36 | INFO | Loading dataset from huggingface.\n",
      "D2: <dict object at 0x7f5f50364aa0>\n",
      "T4: <class 'datasets.data_files.DataFilesDict'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f62d164b0>\n",
      "T4: <class 'datasets.data_files.DataFilesList'>\n",
      "# T4\n",
      "T4: <class 'datasets.data_files.Url'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f62d1a870>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f62d1a550>\n",
      "# D2\n",
      "# D2\n",
      "# D2\n",
      "2025-01-13,21:10:37 | INFO | Using custom data configuration AbhishekSureddy--uniqlo_curated_100-72efc4f3c56b5e50\n",
      "2025-01-13,21:10:37 | INFO | Overwrite dataset info from restored data version if exists.\n",
      "2025-01-13,21:10:37 | INFO | Loading Dataset info from /home/abhisheksureddy/.cache/huggingface/datasets/AbhishekSureddy___parquet/AbhishekSureddy--uniqlo_curated_100-72efc4f3c56b5e50/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7\n",
      "2025-01-13,21:10:37 | WARNING | Found cached dataset parquet (/home/abhisheksureddy/.cache/huggingface/datasets/AbhishekSureddy___parquet/AbhishekSureddy--uniqlo_curated_100-72efc4f3c56b5e50/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7)\n",
      "2025-01-13,21:10:37 | INFO | Loading Dataset info from /home/abhisheksureddy/.cache/huggingface/datasets/AbhishekSureddy___parquet/AbhishekSureddy--uniqlo_curated_100-72efc4f3c56b5e50/0.0.0/14a00e99c0d15a23649d0db8944380ac81082d4b021f398733dd84f3a6c569a7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c93448be383647a797fc0211a7b76db6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "T4: <class 'data.utils.Transform'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f53044a00>\n",
      "T4: <class 'open_clip.tokenizer.HFTokenizer'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f5035bd70>\n",
      "T4: <class 'transformers.models.t5.tokenization_t5_fast.T5TokenizerFast'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f50369a00>\n",
      "T4: <class 'tokenizers.Tokenizer'>\n",
      "# T4\n",
      "T4: <class 'tokenizers.models.Model'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f50369af0>\n",
      "D2: <dict object at 0x7f5f50369b40>\n",
      "D2: <dict object at 0x7f5f50369b90>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369be0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369cd0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369d20>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369d70>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369dc0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369eb0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369f00>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369f50>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369fa0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370050>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503700a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503700f0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370140>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370230>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370280>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503702d0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370320>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370410>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370460>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503704b0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370500>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370550>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503705a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503705f0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370640>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370730>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370780>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503707d0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370820>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370910>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370960>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503709b0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370a00>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370a50>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370aa0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370af0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370b40>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370c30>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370c80>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370cd0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370d20>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370e10>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370e60>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370eb0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370f00>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370f50>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50370fa0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376050>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503760a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376190>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503761e0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376230>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376280>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376370>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503763c0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376410>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376460>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503764b0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376500>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376550>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503765a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376690>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503766e0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376730>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376780>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376870>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503768c0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376910>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376960>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503769b0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376a00>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376b90>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50376a50>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50364c80>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50364e60>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50364f50>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50364fa0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369050>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503690a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503690f0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369140>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369190>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503691e0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503692d0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369320>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369370>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503693c0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503694b0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369500>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369550>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503695a0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503695f0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369640>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369690>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503696e0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f503697d0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369820>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354e10>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354d20>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354cd0>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354c80>\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354c30>\n",
      "# D2\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50354b40>\n",
      "# D2\n",
      "# D2\n",
      "D2: <dict object at 0x7f5f50369aa0>\n",
      "# D2\n",
      "# D2\n",
      "F2: <function _clean_canonicalize at 0x7f5f5900def0>\n",
      "# F2\n",
      "# D2\n",
      "T4: <class 'torchvision.transforms.transforms.Compose'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f50340780>\n",
      "T4: <class 'torchvision.transforms.transforms.Resize'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f50340500>\n",
      "T4: <class 'collections.OrderedDict'>\n",
      "# T4\n",
      "T1: <class 'set'>\n",
      "F2: <function _load_type at 0x7f5f7067e0e0>\n",
      "# F2\n",
      "# T1\n",
      "T4: <enum 'InterpolationMode'>\n",
      "# T4\n",
      "# D2\n",
      "F2: <function _convert_to_rgb at 0x7f5f59107b90>\n",
      "# F2\n",
      "T4: <class 'torchvision.transforms.transforms.ToTensor'>\n",
      "# T4\n",
      "T4: <class 'torchvision.transforms.transforms.Normalize'>\n",
      "# T4\n",
      "D2: <dict object at 0x7f5f503403c0>\n",
      "# D2\n",
      "# D2\n",
      "# D2\n",
      "2025-01-13,21:10:37 | INFO | Number of document rows: 106\n"
     ]
    }
   ],
   "source": [
    "doc_dataset, item_ID = get_dataset(args, tokenizer, preprocess)\n",
    "logging.info(f\"Number of document rows: {len(doc_dataset):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13,21:10:37 | INFO | Loading embeddings of documents\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isfile(args.embeddings_path) or args.overwrite_embeddings:\n",
    "    logging.info(\"Getting embeddings of documents\")\n",
    "    embeddings = get_embeddings(model, doc_dataset, args)\n",
    "    torch.save(embeddings, args.embeddings_path)\n",
    "else:\n",
    "    logging.info(\"Loading embeddings of documents\")\n",
    "    embeddings = torch.load(args.embeddings_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for Uniqlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-13,21:29:10 | INFO | Task: {\n",
      "    \"name\": \"image-to-image\",\n",
      "    \"query_col\": [\n",
      "        \"image\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\"\n",
      "    ]\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Loading retrieval\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.0\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.0\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.0\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.0\n",
      "    },\n",
      "    \"MRR\": 0.22222\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Loading retrieval\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0799\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0182\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0299\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0182\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0582\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0600\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.01818,\n",
      "        \"MAP@10\": 0.02985\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.2,\n",
      "        \"NDCG@10\": 0.07991\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.2,\n",
      "        \"P@10\": 0.06\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.01818,\n",
      "        \"Recall@10\": 0.05818\n",
      "    },\n",
      "    \"MRR\": 0.26667\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Loading retrieval\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0706\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0133\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0192\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0133\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0497\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0600\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.01333,\n",
      "        \"MAP@10\": 0.01924\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.2,\n",
      "        \"NDCG@10\": 0.07063\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.2,\n",
      "        \"P@10\": 0.06\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.01333,\n",
      "        \"Recall@10\": 0.0497\n",
      "    },\n",
      "    \"MRR\": 0.225\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Loading retrieval\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0278\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0091\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0182\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0200\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.00909\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.02777\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.02\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.01818\n",
      "    },\n",
      "    \"MRR\": 0.125\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Collar/ground_truth_image-image.json\n",
      "./data/uniqlo_curated/Color/ground_truth_image-image.json\n",
      "./data/uniqlo_curated/Material/ground_truth_image-image.json\n",
      "./data/uniqlo_curated/Sleeve/ground_truth_image-image.json\n",
      "./data/uniqlo_curated/Texture/Pattern/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 65.41it/s]\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0772\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0250\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0315\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0250\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0650\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0600\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.025,\n",
      "        \"MAP@10\": 0.0315\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.2,\n",
      "        \"NDCG@10\": 0.0772\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.2,\n",
      "        \"P@10\": 0.06\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.025,\n",
      "        \"Recall@10\": 0.065\n",
      "    },\n",
      "    \"MRR\": 0.225\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Type/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 66.50it/s]\n",
      "2025-01-13,21:29:10 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:10 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | NDCG@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | NDCG@10: 0.0440\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | MAP@1: 0.0143\n",
      "2025-01-13,21:29:10 | INFO | MAP@10: 0.0143\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | Recall@1: 0.0143\n",
      "2025-01-13,21:29:10 | INFO | Recall@10: 0.0143\n",
      "2025-01-13,21:29:10 | INFO | \n",
      "\n",
      "2025-01-13,21:29:10 | INFO | P@1: 0.2000\n",
      "2025-01-13,21:29:10 | INFO | P@10: 0.0200\n",
      "2025-01-13,21:29:10 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.01429,\n",
      "        \"MAP@10\": 0.01429\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.2,\n",
      "        \"NDCG@10\": 0.04402\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.2,\n",
      "        \"P@10\": 0.02\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.01429,\n",
      "        \"Recall@10\": 0.01429\n",
      "    },\n",
      "    \"MRR\": 0.2\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Task: {\n",
      "    \"name\": \"image-to-image_text\",\n",
      "    \"query_col\": [\n",
      "        \"image\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"item_name\",\n",
      "        \"materials\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.8,\n",
      "        0.1,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-13,21:29:10 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:10 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Collar/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 68.23it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.0\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.0\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.0\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.0\n",
      "    },\n",
      "    \"MRR\": 0.04\n",
      "}\n",
      "2025-01-13,21:29:11 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:11 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Color/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 70.28it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0655\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0264\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0582\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0600\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.02636\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.06546\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.06\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.05818\n",
      "    },\n",
      "    \"MRR\": 0.13333\n",
      "}\n",
      "2025-01-13,21:29:11 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:11 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Material/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 71.16it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0795\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0227\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0630\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0800\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.02267\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.07953\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.08\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.06303\n",
      "    },\n",
      "    \"MRR\": 0.16667\n",
      "}\n",
      "2025-01-13,21:29:11 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:11 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Sleeve/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 71.26it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.0\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.0\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.0\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.0\n",
      "    },\n",
      "    \"MRR\": 0.08667\n",
      "}\n",
      "2025-01-13,21:29:11 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:11 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Texture/Pattern/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 71.81it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0856\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0322\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0900\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0800\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.03217\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.08558\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.08\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.09\n",
      "    },\n",
      "    \"MRR\": 0.16667\n",
      "}\n",
      "2025-01-13,21:29:11 | INFO | Loading ground truth\n",
      "2025-01-13,21:29:11 | INFO | Running retrieval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/uniqlo_curated/Type/ground_truth_image-image.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:00<00:00, 72.47it/s]\n",
      "2025-01-13,21:29:11 | INFO | Evaluation Starts\n",
      "2025-01-13,21:29:11 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | NDCG@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | NDCG@10: 0.0405\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | MAP@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | MAP@10: 0.0100\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | Recall@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | Recall@10: 0.0286\n",
      "2025-01-13,21:29:11 | INFO | \n",
      "\n",
      "2025-01-13,21:29:11 | INFO | P@1: 0.0000\n",
      "2025-01-13,21:29:11 | INFO | P@10: 0.0400\n",
      "2025-01-13,21:29:11 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.0,\n",
      "        \"MAP@10\": 0.01\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0,\n",
      "        \"NDCG@10\": 0.0405\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0,\n",
      "        \"P@10\": 0.04\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.0,\n",
      "        \"Recall@10\": 0.02857\n",
      "    },\n",
      "    \"MRR\": 0.1\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Run tasks for curated uniqlo\n",
    "# The metrics structure is slightly different here\n",
    "metric_ways = [\"Collar\", \"Color\", \"Material\", \"Sleeve\", \"Texture/Pattern\", \"Type\"]\n",
    "for task in args.dataset_config[\"tasks\"]:\n",
    "    task_dir = os.path.join(args.output_dir, task['name'])\n",
    "    if not os.path.exists(task_dir):\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "    logging.info(f'Task: {json.dumps(task, indent=4)}')\n",
    "    for metric_way in metric_ways:\n",
    "        for query_col in task[\"query_col\"]:\n",
    "            gt_dir = os.path.join(args.data_dir, \"uniqlo_curated\", metric_way)\n",
    "            gt_results_path = os.path.join(gt_dir, f\"ground_truth_{query_col}-{'+'.join(['image'])}.json\")\n",
    "            print(gt_results_path)\n",
    "            assert os.path.exists(gt_results_path)\n",
    "\n",
    "            # Ground-truth query-doc\n",
    "            logging.info(\"Loading ground truth\")\n",
    "            with open(gt_results_path, \"r\") as f:\n",
    "                gt_results = json.load(f)\n",
    "                test_queries = list(gt_results.keys()) # randomly sampled queries (up to 2000)\n",
    "            \n",
    "            # Running retrieval\n",
    "            retrieval_path = os.path.join(task_dir, f\"{metric_way.replace('/','_')}_retrieved_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "            if os.path.exists(retrieval_path) and not args.overwrite_retrieval:\n",
    "                logging.info(\"Loading retrieval\")\n",
    "                with open(retrieval_path, \"r\") as f:\n",
    "                    retrieval_results = json.load(f)\n",
    "            else:\n",
    "                logging.info(\"Running retrieval\")\n",
    "                if len(task['doc_col'])==1:\n",
    "                    doc_embeddings = embeddings[task['doc_col'][0]].to(args.device)\n",
    "                else:\n",
    "                    assert ('doc_weights' in task and len(task['doc_weights'])==len(task['doc_col'])), \\\n",
    "                        \"Must provide the same number of weights for multi-field documents as the number of multi-fields.\"\n",
    "                    doc_embeddings = F.normalize(torch.stack([w*embeddings[c] for c, w in zip(task['doc_col'], task['doc_weights'])], dim=1).sum(1), dim=-1).to(args.device)\n",
    "                retrieval_results = run_retrieval(test_queries, item_ID, doc_embeddings, tokenizer, model, max(args.Ks), args)\n",
    "                with open(retrieval_path, \"w\") as f:\n",
    "                    json.dump(retrieval_results, f, indent=4)\n",
    "\n",
    "            # Evaluation Starts\n",
    "            logging.info(\"Evaluation Starts\")\n",
    "            output_results = evaluate_retrieval(gt_results, retrieval_results, args)\n",
    "            output_json = os.path.join(task_dir, f\"result_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "            output_json_dict = json.dumps(output_results, indent=4)\n",
    "            logging.info(output_json_dict)\n",
    "            with open(output_json, 'w') as f:\n",
    "                f.write(output_json_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics for other datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-07,00:07:58 | INFO | Task: {\n",
      "    \"name\": \"text-to-image\",\n",
      "    \"query_col\": [\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\"\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:07:58 | INFO | Loading ground truth\n",
      "2025-01-07,00:07:58 | INFO | Running retrieval\n",
      "100%|██████████| 2000/2000 [01:32<00:00, 21.56it/s]\n",
      "2025-01-07,00:09:31 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:31 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | NDCG@1: 0.0630\n",
      "2025-01-07,00:09:31 | INFO | NDCG@10: 0.1365\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | MAP@1: 0.0624\n",
      "2025-01-07,00:09:31 | INFO | MAP@10: 0.1075\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | Recall@1: 0.0624\n",
      "2025-01-07,00:09:31 | INFO | Recall@10: 0.2297\n",
      "2025-01-07,00:09:31 | INFO | \n",
      "\n",
      "2025-01-07,00:09:31 | INFO | P@1: 0.0630\n",
      "2025-01-07,00:09:31 | INFO | P@10: 0.0238\n",
      "2025-01-07,00:09:32 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.06242,\n",
      "        \"MAP@10\": 0.10752\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.063,\n",
      "        \"NDCG@10\": 0.13649\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.063,\n",
      "        \"P@10\": 0.02375\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.06242,\n",
      "        \"Recall@10\": 0.2297\n",
      "    },\n",
      "    \"MRR\": 0.10791\n",
      "}\n",
      "2025-01-07,00:09:32 | INFO | Task: {\n",
      "    \"name\": \"category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category1\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:32 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:32 | INFO | Running retrieval\n",
      "100%|██████████| 5/5 [00:00<00:00, 21.51it/s]\n",
      "2025-01-07,00:09:33 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:33 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | NDCG@1: 1.0000\n",
      "2025-01-07,00:09:33 | INFO | NDCG@10: 0.9843\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | MAP@1: 0.0000\n",
      "2025-01-07,00:09:33 | INFO | MAP@10: 0.0003\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | Recall@1: 0.0000\n",
      "2025-01-07,00:09:33 | INFO | Recall@10: 0.0003\n",
      "2025-01-07,00:09:33 | INFO | \n",
      "\n",
      "2025-01-07,00:09:33 | INFO | P@1: 1.0000\n",
      "2025-01-07,00:09:33 | INFO | P@10: 0.9800\n",
      "2025-01-07,00:09:33 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 3e-05,\n",
      "        \"MAP@10\": 0.00026\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 1.0,\n",
      "        \"NDCG@10\": 0.98432\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 1.0,\n",
      "        \"P@10\": 0.98\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 3e-05,\n",
      "        \"Recall@10\": 0.00027\n",
      "    },\n",
      "    \"MRR\": 1.0\n",
      "}\n",
      "2025-01-07,00:09:33 | INFO | Task: {\n",
      "    \"name\": \"sub-category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category2\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:33 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:33 | INFO | Running retrieval\n",
      "100%|██████████| 31/31 [00:01<00:00, 21.68it/s]\n",
      "2025-01-07,00:09:35 | INFO | Evaluation Starts\n",
      "2025-01-07,00:09:35 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | NDCG@1: 0.6129\n",
      "2025-01-07,00:09:35 | INFO | NDCG@10: 0.6035\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | MAP@1: 0.0002\n",
      "2025-01-07,00:09:35 | INFO | MAP@10: 0.0013\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | Recall@1: 0.0002\n",
      "2025-01-07,00:09:35 | INFO | Recall@10: 0.0015\n",
      "2025-01-07,00:09:35 | INFO | \n",
      "\n",
      "2025-01-07,00:09:35 | INFO | P@1: 0.6129\n",
      "2025-01-07,00:09:35 | INFO | P@10: 0.6032\n",
      "2025-01-07,00:09:35 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.00017,\n",
      "        \"MAP@10\": 0.00129\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.6129,\n",
      "        \"NDCG@10\": 0.6035\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.6129,\n",
      "        \"P@10\": 0.60323\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.00017,\n",
      "        \"Recall@10\": 0.0015\n",
      "    },\n",
      "    \"MRR\": 0.73342\n",
      "}\n",
      "2025-01-07,00:09:35 | INFO | Task: {\n",
      "    \"name\": \"fine-category-to-product\",\n",
      "    \"query_col\": [\n",
      "        \"category3\"\n",
      "    ],\n",
      "    \"doc_col\": [\n",
      "        \"image\",\n",
      "        \"text\"\n",
      "    ],\n",
      "    \"doc_weights\": [\n",
      "        0.9,\n",
      "        0.1\n",
      "    ]\n",
      "}\n",
      "2025-01-07,00:09:35 | INFO | Loading ground truth\n",
      "2025-01-07,00:09:35 | INFO | Running retrieval\n",
      "100%|██████████| 2000/2000 [01:32<00:00, 21.61it/s]\n",
      "2025-01-07,00:11:08 | INFO | Evaluation Starts\n",
      "2025-01-07,00:11:08 | INFO | For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | NDCG@1: 0.0805\n",
      "2025-01-07,00:11:08 | INFO | NDCG@10: 0.1075\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | MAP@1: 0.0391\n",
      "2025-01-07,00:11:08 | INFO | MAP@10: 0.0783\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | Recall@1: 0.0391\n",
      "2025-01-07,00:11:08 | INFO | Recall@10: 0.1460\n",
      "2025-01-07,00:11:08 | INFO | \n",
      "\n",
      "2025-01-07,00:11:08 | INFO | P@1: 0.0805\n",
      "2025-01-07,00:11:08 | INFO | P@10: 0.0374\n",
      "2025-01-07,00:11:08 | INFO | {\n",
      "    \"mAP\": {\n",
      "        \"MAP@1\": 0.03915,\n",
      "        \"MAP@10\": 0.07826\n",
      "    },\n",
      "    \"ndcg\": {\n",
      "        \"NDCG@1\": 0.0805,\n",
      "        \"NDCG@10\": 0.10754\n",
      "    },\n",
      "    \"precision\": {\n",
      "        \"P@1\": 0.0805,\n",
      "        \"P@10\": 0.0374\n",
      "    },\n",
      "    \"recall\": {\n",
      "        \"Recall@1\": 0.03915,\n",
      "        \"Recall@10\": 0.14596\n",
      "    },\n",
      "    \"MRR\": 0.11935\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Run tasks\n",
    "for task in args.dataset_config[\"tasks\"]:\n",
    "    task_dir = os.path.join(args.output_dir, task['name'])\n",
    "    if not os.path.exists(task_dir):\n",
    "        os.makedirs(task_dir, exist_ok=True)\n",
    "    logging.info(f'Task: {json.dumps(task, indent=4)}')\n",
    "\n",
    "    for query_col in task[\"query_col\"]:\n",
    "        gt_dir = os.path.join(args.data_dir, args.dataset_config[\"name\"], 'gt_query_doc')\n",
    "        gt_results_path = os.path.join(gt_dir, f\"ground_truth_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        assert os.path.exists(gt_results_path)\n",
    "\n",
    "        # Ground-truth query-doc\n",
    "        logging.info(\"Loading ground truth\")\n",
    "        with open(gt_results_path, \"r\") as f:\n",
    "            gt_results = json.load(f)\n",
    "            test_queries = list(gt_results.keys()) # randomly sampled queries (up to 2000)\n",
    "        \n",
    "        # Running retrieval\n",
    "        retrieval_path = os.path.join(task_dir, f\"retrieved_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        if os.path.exists(retrieval_path) and not args.overwrite_retrieval:\n",
    "            logging.info(\"Loading retrieval\")\n",
    "            with open(retrieval_path, \"r\") as f:\n",
    "                retrieval_results = json.load(f)\n",
    "        else:\n",
    "            logging.info(\"Running retrieval\")\n",
    "            if len(task['doc_col'])==1:\n",
    "                doc_embeddings = embeddings[task['doc_col'][0]].to(args.device)\n",
    "            else:\n",
    "                assert ('doc_weights' in task and len(task['doc_weights'])==len(task['doc_col'])), \\\n",
    "                    \"Must provide the same number of weights for multi-field documents as the number of multi-fields.\"\n",
    "                doc_embeddings = F.normalize(torch.stack([w*embeddings[c] for c, w in zip(task['doc_col'], task['doc_weights'])], dim=1).sum(1), dim=-1).to(args.device)\n",
    "            retrieval_results = run_retrieval(test_queries, item_ID, doc_embeddings, tokenizer, model, max(args.Ks), args)\n",
    "            with open(retrieval_path, \"w\") as f:\n",
    "                json.dump(retrieval_results, f, indent=4)\n",
    "\n",
    "        # Evaluation Starts\n",
    "        logging.info(\"Evaluation Starts\")\n",
    "        output_results = evaluate_retrieval(gt_results, retrieval_results, args)\n",
    "        output_json = os.path.join(task_dir, f\"result_{query_col}-{'+'.join(task['doc_col'])}.json\")\n",
    "        output_json_dict = json.dumps(output_results, indent=4)\n",
    "        logging.info(output_json_dict)\n",
    "        with open(output_json, 'w') as f:\n",
    "            f.write(output_json_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
